# 第五章 Shapley值

可以通过假设实例的每个特征值是预测是支付的游戏中的“玩家”来解释预测。 Shapley值 - 一种来自联盟博弈论的方法 - 告诉我们如何在特征中公平地分配“支付”。

5.8.1一般想法
假设以下场景：

您已经培训了机器学习模型来预测公寓价格。对于某个公寓，它预测为300,000欧元，你需要解释这个预测。公寓面积为50平方米，位于二楼，附近有一个公园，禁止猫咪：

 50平方公尺二楼公寓的预计价格为300,000欧元，附近有公园和猫禁令。我们的目标是解释每个特征值如何促成预测。
![图5.37：50平方米的二楼公寓的预计价格为300,000欧元，附近有公园和禁令。我们的目标是解释每个特征值如何促成预测。](https://raw.githubusercontent.com/buptss/Interpretable-Machine-Learning/gh-pages/Model_Agnostic_Methods/shapley-instance.png)


所有公寓的平均预测为310,000欧元。与平均预测相比，每个特征值对预测的贡献是多少？

线性回归模型的答案很简单。每个要素的效果是要素的权重乘以要素值。这仅适用于模型的线性。对于更复杂的模型，我们需要不同的解决方案。例如，LIME建议本地模型来估计影响。另一种解决方案来自合作博弈论：由Shapley（1953）创造的Shapley值是一种根据玩家对总支出的贡献来为玩家分配支出的方法。球员在联盟中合作并从这种合作中获得一定的利润。

球员呢？游戏？赔付？与机器学习预测和可解释性有什么联系？ “游戏”是数据集的单个实例的预测任务。 “增益”是该实例的实际预测减去所有实例的平均预测。 “玩家”是协作接收增益的实例的特征值（=预测某个值）。在我们的公寓示例中，附近的公园，禁止猫，50区和2楼的特征值共同实现了300,000欧元的预测。我们的目标是解释实际预测（300,000欧元）和平均预测（310,000欧元）之间的差异：相差10,000欧元。

答案可能是：附近的公园贡献了30,000欧元; 50码贡献了10,000欧元;第二名贡献了0欧元;被禁止捐赠 -  50,000欧元。这笔捐款加起来 - €10,000，最终预测减去平均预测的公寓价格。

我们如何计算一个特征的Shapley值？

Shapley值是所有可能联盟中特征值的平均边际贡献。一切都清楚了吗？

在下图中，我们评估了cat禁用特征值在添加到附近公园和大小为50的联盟时的贡献。我们通过从数据中随机抽取另一个公寓并使用其值作为地板特征来模拟只有附近的公园，被禁止的猫和50号大小的联盟。值floor-2nd被随机抽取的floor-1st取代。然后我们用这种组合预测公寓的价格（310,000欧元）。在第二步中，我们通过用随机绘制的公寓中猫允许/禁止特征的随机值替换它来从联盟中删除被禁止的猫。在这个例子中，它是猫允许的，但它可能已经被禁止了。我们预测附近公园联盟的公寓价格为50（€320,000）。被禁猫的贡献是310,000欧元 -  320,000欧元= --10,000欧元。该估计值取决于随机抽取的公寓的值，该公寓充当猫和地板特征值的“捐助者”。如果我们重复这个采样步骤并平均贡献，我们将得到更好的估计。

 一个样本重复，以估计“cat-banned”对预测的贡献，当加入“park-near”和“area-50”联盟时。
图5.38：一个样本重复，用于估算被加入到附近公园和50区的联盟时被禁止对预测的贡献。

我们对所有可能的联盟重复这个计算。 Shapley值是所有可能联盟的所有边际贡献的平均值。计算时间随着特征的数量呈指数增长。保持计算时间可管理的一种解决方案是仅计算可能联盟的少数样本的贡献。

下图显示了确定cat-banned的Shapley值所需的所有特征值联盟。第一行显示没有任何特征值的联盟。第二，第三和第四行显示出不同的联盟，联盟规模越来越大，以“|”分隔。总而言之，以下联盟是可能的：

没有功能值
公园附近
大小50
地板第二
公园附近的+尺寸50
公园附近的+落地式第二
大小-50 +
公园附近 + 大小：50 + 第二层楼

对于每一种组合，我们分别计算具有和不具有特征值cat- forbidden的预测公寓价格，并取其差值得到边际贡献。Shapley值是边际贡献的(加权)平均值。我们将不属于联盟的特征值替换为来自公寓数据集的随机特征值，以获得来自机器学习模型的预测。



所有8个联盟需要计算确切的Shapley值的“猫禁”功能值。

图5.39:计算cat禁用特性值的确切Shapley值所需的所有8个联合。



如果我们对所有特征值的Shapley值进行估计，我们就得到了预测值(减去平均值)在特征值之间的完整分布。



5.8.2例子和解释

对特征值j的Shapley值的解释是:贡献的第j个特征的值

ϕ

j

将此特定实例的预测与数据集的平均预测进行比较。



Shapley值适用于分类(如果我们处理的是概率)和回归。



我们使用Shapley值来分析预测子宫颈癌的随机森林模型的预测:



Shapley值，用于宫颈癌数据集中的女性。预测为0.43，这名妇女患癌症的概率比平均预测的0.03高出0.41。被诊断为性病的人数增加的可能性最大。贡献的总和产生实际预测与平均预测之间的差额(0.41)。

图5.40:宫颈癌数据集中女性的Shapley值。预测为0.43，这名妇女患癌症的概率比平均预测的0.03高出0.41。被诊断为性病的人数增加的可能性最大。贡献的总和产生实际预测与平均预测之间的差额(0.41)。



对于自行车租赁数据集，我们还训练一个随机森林来预测给定天气和日历信息下一天租用的自行车数量。对某一天随机森林预测的解释如下:



第285天的Shapley值。预计有2329辆出租自行车，比4517辆的平均预测低2189辆。而天气状况和湿度对其负影响最大。这一天的气温也起到了积极的作用。Shapley值之和等于实际预测值与平均预测值的差值(-2189)。

图5.41:第285天的Shapley值。预计有2329辆出租自行车，比4517辆的平均预测低2189辆。而天气状况和湿度对其负影响最大。这一天的气温也起到了积极的作用。Shapley值之和等于实际预测值与平均预测值的差值(-2189)。



注意正确解释Shapley值:Shapley值是特征值对不同联合预测的平均贡献。Shapley值并不是我们从模型中删除特征时预测的差异。



5.8.3 Shapley值详细说明

对于好奇的读者，本节将更深入地介绍Shapley值的定义和计算。如果您对技术细节不感兴趣，请跳过此部分，直接进入“优缺点”。



我们感兴趣的是每个特性如何影响数据点的预测。在线性模型中，计算单个效应是很容易的。下面是一个数据实例的线性模型预测:



^

f

(

x

)

=

β

0

+

β

1

x

1

+

...

+

β

p

x

p





其中x是我们要计算贡献的实例。每一个

x

j

为特征值，j = 1，…，p。的

β

j

为特征j对应的权值。



的贡献

ϕ

j

对第j个特征进行了预测

^

f

(

x

)

是:



ϕ

j

(

^

f

)

=

β

j

x

j

−

E

(

β

j

X

j

)

=

β

j

x

j

−

β

j

E

(

X

j

)





在哪里

E

(

β

j

X

j

)

为特征j的平均效果估计，贡献为特征效果减去平均效果之差。好了!现在我们知道每个特性对预测的贡献有多大。如果我们将一个实例的所有特性贡献相加，结果如下:



p

∑

j

=

1



ϕ

j

(

^

f

)

=

p

∑

j

=

1



(

β

j

x

j

−

E

(

β

j

X

j

)

)

=

(

β

0

+

p

∑

j

=

1



β

j

x

j

)

−

(

β

0

+

p

∑

j

=

1



E

(

β

j

X

j

)

)

=

^

f

(

x

)

−

E

(

^

f

(

X

)

)





这是数据点x的预测值减去平均值。特性贡献可能是负面的。



我们能对任何类型的模型做同样的事情吗?将其作为一个与模型无关的工具将是非常棒的。由于我们通常在其他模型类型中没有类似的权重，所以我们需要一个不同的解决方案。



帮助来自意想不到的地方:合作博弈论。Shapley值是计算任何机器学习模型的单个预测的特征贡献的解决方案。

5.8.3.1 Shapley值

Shapley值是通过S中参与者的值函数val定义的。



特征值的Shapley值是它对支付的贡献，加权并对所有可能的特征值组合求和:



ϕ

j

(

v

一个

l

)

=

∑

年代

⊆

{

x

1

,

...

,

x

p

}

∖

{

x

j

}



|

年代

|

!

(

p

−

|

年代

|

−

1

)

!

p

!

(

v

一个

l

(

年代

∪

{

x

j

}

)

−

v

一个

l

(

年代

)

)





其中S为模型中使用的特征子集，x为待解释实例的特征值向量，p为特征个数。

v

一个

l

x

(

年代

)

是对集合S中被边缘化的特征值相对于集合S中不包含的特征值的预测:



v

一个

l

x

(

年代

)

=

请执行

^

f

(

x

1

,

...

,

x

p

)

d

P

x

让你

年代

−

E

X

(

^

f

(

X

)

)





你实际上对每一个不包含S的特征进行多重积分。一个具体的例子:机器学习模型有4个特征x1, x2, x3和x4，我们评估由特征值x1和x3组成的联合S的预测:



v

一个

l

x

(

年代

)

=

v

一个

l

x

(

{

x

1

,

x

3.

}

)

=

请执行

R

请执行

R

^

f

(

x

1

,

X

2

,

x

3.

,

X

4

)

d

P

X

2

X

4

−

E

X

(

^

f

(

X

)

)





这看起来类似于线性模型中的特性贡献!



不要被“值”这个词的许多用法所混淆:特征值是特征和实例的数值或分类值;Shapley值为特征对预测的贡献;价值函数是玩家联盟的支付函数(特征值)。



Shapley值是唯一一种满足属性效率、对称性、虚拟性和可加性的归属方法，它可以被认为是公平支付的定义。



效率

特征贡献必须加起来等于x和平均值的预测差。



∑

p

j

=

1

ϕ

j

=

^

f

(

x

)

−

E

X

(

^

f

(

X

)

)





对称

如果两个特征值j和k对所有可能的联合的贡献相同，那么它们的贡献应该是相同的。如果



v

一个

l

(

年代

∪

{

x

j

}

)

=

v

一个

l

(

年代

∪

{

x

k

}

)





对所有



年代

⊆

{

x

1

,

...

,

x

p

}

∖

{

x

j

,

x

k

}





然后



ϕ

j

=

ϕ

k





假

一个不改变预测值的特征j——不管它被添加到哪个特征值的组合中——应该有一个Shapley值为0。如果



v

一个

l

(

年代

∪

{

x

j

}

)

=

v

一个

l

(

年代

)





对所有



年代

⊆

{

x

1

,

...

,

x

p

}





然后



ϕ

j

=

0





可加性

对于收益为val+val+的游戏，Shapley值分别为:



ϕ

j

+

ϕ

+

j





假设你训练了一个随机森林，这意味着预测是许多决策树的平均值。可加性属性保证对于一个特征值，您可以分别计算每棵树的Shapley值，对它们求平均值，并得到随机森林的特征值的Shapley值。



5.8.3.2直觉

理解Shapley值的直观方法如下图所示:特征值以随机顺序进入房间。房间内的所有特征值都参与游戏(=有助于预测)。特征值的Shapley值是特征值加入房间中已经存在的联盟所接收到的预测的平均变化。



5.8.3.3 Shapley值的估计

所有可能的特征值联合(集)都必须使用和不使用第j个特征来计算确切的Shapley值。对于多个特性，随着添加更多特性，可能的联合的数量呈指数级增长，这个问题的确切解决方案就会出现问题。Strumbelj等人(2014)40提出了蒙特卡罗抽样近似:



^

ϕ

j

=

1

米

米

∑

米

=

1



(

^

f

(

x

米

+

j

)

−

^

f

(

x

米

−

j

)

)





在哪里

^

f

(

x

米

+

j

)

是对x的预测，但是用随机个数的特征值替换一个随机数据点z的特征值，除了各自的特征值j

x

米

−

j

几乎与

x

米

+

j

，但是

x

米

j

也取自采样的x。这M个新实例中的每一个都是由两个实例组装而成的一种“弗兰肯斯坦怪物”。



单特征值近似Shapley估计:



输出:Shapley值为第j个特征值

要求:迭代次数M，兴趣实例x，特征索引j，数据矩阵x，机器学习模型f

对于所有m = 1，…，m:

从数据矩阵X中随机抽取实例z

选择特征值的随机排列o

订购实例x:

x

o

=

(

x

(

1

)

,

...

,

x

(

j

)

,

...

,

x

(

p

)

)



订购实例z:

z

o

=

(

z

(

1

)

,

...

,

z

(

j

)

,

...

,

z

(

p

)

)



构造两个新实例

j与特点:

x

+

j

=

(

x

(

1

)

,

...

,

x

(

j

−

1

)

,

x

(

j

)

,

z

(

j

+

1

)

,

...

,

z

(

p

)

)



没有特性j:

x

−

j

=

(

x

(

1

)

,

...

,

x

(

j

−

1

)

,

z

(

j

)

,

z

(

j

+

1

)

,

...

,

z

(

p

)

)



计算边际贡献:

ϕ

米

j

=

^

f

(

x

+

j

)

−

^

f

(

x

−

j

)



计算Shapley值的平均值:

ϕ

j

(

x

)

=

1

米

∑

米

米

=

1

ϕ

米

j



首先，选择一个感兴趣的实例x，一个特征j，迭代次数m。每次迭代，从数据中选择一个随机的实例z，生成特征的随机顺序。通过组合感兴趣的x实例和示例z的值创建两个新实例

x

+

j

是感兴趣的实例，但是所有按之前的顺序和包含特征j的值的值都被来自样本z的特征值替换。第二个实例

x

−

j

相似，但是所有的值都是按之前的顺序排列的，但不包括特征j被样本z中特征j的值所替代。计算黑盒子预测的差异:



ϕ

米

j

=

^

f

(

x

米

+

j

)

−

^

f

(

x

米

−

j

)





所有这些差异均取平均值，结果如下:



ϕ

j

(

x

)

=

1

米

米

∑

米

=

1



ϕ

米

j





通过X的概率分布隐式加权样本。



必须对每个特性重复该过程才能获得所有Shapley值。



5.8.4优势

预测与平均预测之间的差异在实例的特征值——Shapley值的效率特性值之间有较好的分布。此属性将Shapley值与其他方法(如LIME)区分开来。LIME并不能保证预测在特征之间是公平分布的。Shapley值可能是提供完整解释的唯一方法。在法律要求可解释性的情况下——比如欧盟的“解释权”——Shapley值可能是唯一符合法律的方法，因为它基于坚实的理论，公平地分配效果。我不是律师，所以这只反映了我对要求的直觉。



Shapley值允许对比解释。您可以将预测与整个数据集的平均预测进行比较，而不是将其与子集甚至单个数据点进行比较。这种对比也是像LIME这样的本地模型所没有的。



Shapley值是唯一具有坚实理论基础的解释方法。效率、对称性、虚拟性、可加性等公理为解释提供了合理的依据。像LIME这样的方法假定机器学习模型的线性行为是局部的，但是没有理论来解释为什么它会起作用。



将预测解释为由特征值所玩的游戏是令人兴奋的。


5.8.5缺点

Shapley值需要大量的计算时间。在99.9%的实际问题中，只有近似解是可行的。Shapley值的精确计算在计算上是昂贵的，因为有2k种可能的特征值联合，并且必须通过绘制随机实例来模拟特征的“缺失”，这增加了Shapley值估计的方差。通过采样联盟数和限制迭代次数M来处理联盟数的指数，M的减小减少了计算时间，但增加了Shapley值的方差。对于迭代次数M没有很好的经验法则，M应该足够大，可以准确地估计Shapley值，但是足够小，可以在合理的时间内完成计算。应该可以根据切诺夫界限选择M，但是我还没有看到任何关于机器学习预测的Shapley值的论文。



Shapley值可能会被误解。特征值的Shapley值不等于模型训练中剔除特征后的预测值的差值。Shapley值的解释是:给定当前的一组特征值，特征值对实际预测值与平均预测值之差的贡献为估计的Shapley值。



如果您寻求稀疏解释(包含很少特性的解释)，Shapley值是错误的解释方法。使用Shapley value方法创建的解释总是使用所有特性。人类更喜欢有选择性的解释，比如石灰产生的解释。对于外行人来说，石灰可能是更好的解释选择。另一种解决方案是由Lundberg和Lee(2016)41提出的SHAP，该方案基于Shapley值，但也可以提供一些特性较少的解释。



Shapley值为每个特性返回一个简单的值，但是没有像LIME那样的预测模型。这意味着它不能用于对输入变化的预测变化作出陈述，例如:“如果我一年多赚300欧元，我的信用评分将提高5分。”



另一个缺点是，如果想计算新数据实例的Shapley值，就需要访问数据。仅访问预测函数是不够的，因为您需要数据用随机抽取的数据实例中的值替换感兴趣的实例的部分。只有当您能够创建看起来像真实数据实例但不是来自培训数据的实际实例的数据实例时，才能避免这种情况。



与许多其他基于置换的解释方法一样，Shapley value方法在特征相关时也会包含不真实的数据实例。为了模拟联合中缺少某个特性值，我们将该特性边缘化。这是通过从特征的边缘分布中采样值来实现的。只要特性是独立的，这就很好。当特性相互依赖时，我们可能会对对该实例没有意义的特性值进行采样。但是我们会用这些来计算特性的Shapley值。据我所知，没有研究这对Shapley价值观意味着什么，也没有建议如何修正它。一种解决方案可能是将相关特性排列在一起，并为它们获得一个相互的Shapley值。或者抽样程序可能需要调整以适应特征的依赖性。

5.8.6软件和备选方案

Shapley值在iml R包中实现。



SHAP是Shapley值的另一种形式，在Python包SHAP中实现。SHAP将Shapley values方法转化为一个优化问题，并使用一个特殊的内核函数来度量数据实例的接近性。SHAP的结果是稀疏的(许多Shapley值估计为零)，这是与经典Shapley值最大的区别。



另一种方法称为分解，它在分解rpackage42中实现。细分还显示了每个特性对预测的贡献，但是要一步一步地计算它们。让我们重新使用游戏类比:我们从一个空团队开始，添加对预测贡献最大的特性值，然后迭代，直到添加所有特性值。每个特性值贡献多少取决于已经在“团队”中的各个特性值，这是分解方法的一大缺点。它比Shapley值方法更快，对于没有交互的模型，结果是相同的。



n人游戏的价值。2.28“贡献理论的游戏(1953):307 - 317。↩

Štrumbelj,埃里克,Igor Kononenko。解释预测模型和个人预测的特征贡献。41.3“知识与信息系统(2014):647 - 665。↩

伦德伯格，斯科特和李素妍。解释模型预测的方法出人意料地统一起来。“arXiv预印本arXiv: 1611.07478 (2016)。↩

斯塔尼亚克，马特乌斯和普热米斯劳·比切克。用活动包和分解包解释模型预测。“arXiv预印本arXiv: 1804.01955 (2018)。↩

